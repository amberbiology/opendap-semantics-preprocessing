{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quick checks of the new fgdc triples structure\n",
    "and maybe the triples (yes the triples, whatevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from semproc.parser import Parser\n",
    "from semproc.preprocessors.metadata_preprocessors import FgdcItemReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the proto-triples example\n",
    "with open('../response_examples/fgdc_proto_example_1.xml', 'r') as f:\n",
    "    response = f.read()\n",
    "\n",
    "# this shouldn't be necessary but cargo-culting here is fine by me.\n",
    "response = response.replace('\\\\\\n', '').replace('\\r\\n', '').replace('\\\\r', '').replace('\\\\n', '').replace('\\n', '')\n",
    "response = response.decode('utf-8', errors='replace').encode('unicode_escape') \n",
    "    \n",
    "url = 'https://bluehub.jrc.ec.europa.eu/erddap/metadata/fgdc/xml/noaa_pfeg_d543_8870_bc7f_fgdc.xml'\n",
    "identities = [\n",
    "    {\"protocol\": \"FGDC\", \n",
    "     \"metadata\": {\n",
    "            \"version\": [\"FGDC Content Standards for Digital Geospatial Metadata, FGDC-STD-001-1998\"], \n",
    "            \"name\": \"FGDC\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "parser = Parser(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# execute the parse (this one takes xml)\n",
    "reader = FgdcItemReader(parser.xml)\n",
    "description = reader.parse_item()\n",
    "\n",
    "# for the faking of things\n",
    "description['catalog_record']['url'] = url\n",
    "description['catalog_record']['harvestDate'] = '2015-06-20T20:22:00.643Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'catalog_record': {'conformsTo': 'http://www.ngdc.noaa.gov/metadata/published/xsd/ngdcSchema/schema.xsd',\n",
       "  'harvestDate': '2015-06-20T20:22:00.643Z',\n",
       "  'url': 'https://bluehub.jrc.ec.europa.eu/erddap/metadata/fgdc/xml/noaa_pfeg_d543_8870_bc7f_fgdc.xml'},\n",
       " 'dataset': {'abstract': 'Navy Global Environmental Model (NAVGEM) is a global numerical weather prediction computer model. It replaced NOGAPS as the prime model in the middle of February 2013 at the Navy Fleet Numerical Meteorology and Oceanography Center (FNMOC) Weather model synoptic site. [Wikipedia]',\n",
       "  'identifier': '',\n",
       "  'spatial_extent': {'east': '180.0',\n",
       "   'north': '90.0',\n",
       "   'south': '-90.0',\n",
       "   'west': '-180.0',\n",
       "   'wkt': 'POLYGON ((-180 -90,-180 90,180 90,180 -90,-180 -90))'},\n",
       "  'title': 'Navy Global Environmental Model (NAVGEM), 0.5 degree, Pressure MSL'},\n",
       " 'keywords': [{'terms': ['conversion',\n",
       "    'data',\n",
       "    'fnmoc',\n",
       "    'level',\n",
       "    'mean',\n",
       "    'navg',\n",
       "    'observed',\n",
       "    'pressure',\n",
       "    'sea',\n",
       "    'theortically',\n",
       "    'value'],\n",
       "   'thesaurus': 'Uncontrolled',\n",
       "   'type': 'theme'},\n",
       "  {'terms': ['time', 'latitude', 'longitude'],\n",
       "   'thesaurus': 'CF Standard Name Table v27',\n",
       "   'type': 'theme'}],\n",
       " 'publisher': {'location': 'Ispra, VA, Italy',\n",
       "  'name': 'ERDDAP, version 1.60, at Maritime Affairs Unit of the Joint Research Centre'},\n",
       " 'temporal_extent': {'endDate': '20140813', 'startDate': '20130215'},\n",
       " 'webpages': [{'url': 'https://bluehub.jrc.ec.europa.eu/erddap/griddap/noaa_pfeg_d543_8870_bc7f.html'},\n",
       "  {'url': 'https://bluehub.jrc.ec.europa.eu/erddap/griddap/noaa_pfeg_d543_8870_bc7f.graph'},\n",
       "  {'url': 'https://bluehub.jrc.ec.europa.eu/erddap/wms/noaa_pfeg_d543_8870_bc7f/request'}]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a minorly faked description dict (for the triples)\n",
    "\n",
    "description = {\n",
    "    \"catalog_record\": {\n",
    "        \"conformsTo\": \"http://www.ngdc.noaa.gov/metadata/published/xsd/ngdcSchema/schema.xsd\",\n",
    "        \"harvestDate\": \"2015-06-20T20:22:00.643Z\",\n",
    "        \"url\": \"https://bluehub.jrc.ec.europa.eu/erddap/metadata/fgdc/xml/noaa_pfeg_d543_8870_bc7f_fgdc.xml\"\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"abstract\": \"Navy Global Environmental Model (NAVGEM) is a global numerical weather prediction computer model. It replaced NOGAPS as the prime model in the middle of February 2013 at the Navy Fleet Numerical Meteorology and Oceanography Center (FNMOC) Weather model synoptic site. [Wikipedia]\",\n",
    "        \"identifier\": \"\",\n",
    "        \"spatial_extent\": {\n",
    "            \"east\": \"180.0\",\n",
    "            \"north\": \"90.0\",\n",
    "            \"south\": \"-90.0\",\n",
    "            \"west\": \"-180.0\",\n",
    "            \"wkt\": \"POLYGON ((-180 -90,-180 90,180 90,180 -90,-180 -90))\"\n",
    "        },\n",
    "        \"title\": \"Navy Global Environmental Model (NAVGEM), 0.5 degree, Pressure MSL\",\n",
    "        \"keywords\": [\n",
    "            {\n",
    "                \"terms\": [\n",
    "                    \"conversion\",\n",
    "                    \"data\",\n",
    "                    \"fnmoc\",\n",
    "                    \"level\",\n",
    "                    \"mean\",\n",
    "                    \"navg\",\n",
    "                    \"observed\",\n",
    "                    \"pressure\",\n",
    "                    \"sea\",\n",
    "                    \"theortically\",\n",
    "                    \"value\"\n",
    "                ],\n",
    "                \"thesaurus\": \"Uncontrolled\",\n",
    "                \"type\": \"theme\"\n",
    "            },\n",
    "            {\n",
    "                \"terms\": [\n",
    "                    \"time\",\n",
    "                    \"latitude\",\n",
    "                    \"longitude\"\n",
    "                ],\n",
    "                \"thesaurus\": \"CF Standard Name Table v27\",\n",
    "                \"type\": \"theme\"\n",
    "            }\n",
    "        ],\n",
    "        \"publisher\": {\n",
    "            \"location\": \"Ispra, VA, Italy\",\n",
    "            \"name\": \"ERDDAP, version 1.60, at Maritime Affairs Unit of the Joint Research Centre\"\n",
    "        },\n",
    "        \"temporal_extent\": {\n",
    "            \"endDate\": \"20140813\",\n",
    "            \"startDate\": \"20130215\"\n",
    "        },\n",
    "        \"webpages\": [\n",
    "            {\"url\": \"https://bluehub.jrc.ec.europa.eu/erddap/griddap/noaa_pfeg_d543_8870_bc7f.html\"},\n",
    "            {\"url\": \"https://bluehub.jrc.ec.europa.eu/erddap/griddap/noaa_pfeg_d543_8870_bc7f.graph\"},\n",
    "            {\"url\": \"https://bluehub.jrc.ec.europa.eu/erddap/wms/noaa_pfeg_d543_8870_bc7f/request\"}\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix GeoSPARQL: <http://purl.org/nsidc/bcube/geosparql#> .\n",
      "@prefix bcube: <http://purl.org/nsidc/bcube/bcube#> .\n",
      "@prefix bibo: <http://purl.org/nsidc/bcube/bibo#> .\n",
      "@prefix dc: <http://purl.org/dc/elements/1.1/> .\n",
      "@prefix dcat: <http://purl.org/nsidc/bcube/dcat#> .\n",
      "@prefix dct: <http://purl.org/dc/terms/> .\n",
      "@prefix esip: <http://purl.org/nsidc/bcube/esip#> .\n",
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
      "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix vcard: <http://purl.org/nsidc/bcube/vcard#> .\n",
      "@prefix vivo: <http://purl.org/nsidc/bcube/vivo#> .\n",
      "@prefix xml: <http://www.w3.org/XML/1998/namespace> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "<urn:sha:21a2c32fd74798563eed88a3fcd1acf38092f47e> dc:conformsTo \"http://www.ngdc.noaa.gov/metadata/published/xsd/ngdcSchema/schema.xsd\" ;\n",
      "    vcard:hasURL \"https://bluehub.jrc.ec.europa.eu/erddap/metadata/fgdc/xml/noaa_pfeg_d543_8870_bc7f_fgdc.xml\" ;\n",
      "    vivo:harvestDate \"2015-06-20T20:22:00.643Z\" ;\n",
      "    owl:a dcat:CatalogRecord .\n",
      "\n",
      "<urn:sha:e018c0a1fb2f9fdc497f7f78eede802c833883ef> dc:conformsTo <urn:uuid:3dcf30fc-1a7b-4af9-86cf-ca2c45ac6af6>,\n",
      "        <urn:uuid:d3790ec1-2d11-4230-9097-6479a7efc8f3> ;\n",
      "    dc:description \"Navy Global Environmental Model (NAVGEM) is a global numerical weather prediction computer model. It replaced NOGAPS as the prime model in the middle of February 2013 at the Navy Fleet Numerical Meteorology and Oceanography Center (FNMOC) Weather model synoptic site. [Wikipedia]\" ;\n",
      "    dc:relation <urn:uuid:27693e83-8d46-42a5-a4f6-97f80d4fed0b>,\n",
      "        <urn:uuid:3fde314c-bae5-4985-a04f-f6ff95dee4a0>,\n",
      "        <urn:uuid:f96b1d17-5cf6-4aa8-a4dc-dcc9ed2a3f7e> ;\n",
      "    dc:spatial \"POLYGON ((-180 -90,-180 90,180 90,180 -90,-180 -90))\" ;\n",
      "    dct:identifier \"\" ;\n",
      "    dct:title \"Navy Global Environmental Model (NAVGEM), 0.5 degree, Pressure MSL\" ;\n",
      "    dcat:publisher <urn:uuid:78742f73-6d77-483b-aca3-80059dda8233> ;\n",
      "    esip:eastBound \"180.0\" ;\n",
      "    esip:endDate \"None\" ;\n",
      "    esip:northBound \"90.0\" ;\n",
      "    esip:southBound \"-90.0\" ;\n",
      "    esip:startDate \"20130215\" ;\n",
      "    esip:westBound \"-180.0\" ;\n",
      "    owl:a dcat:Dataset .\n",
      "\n",
      "<urn:uuid:27693e83-8d46-42a5-a4f6-97f80d4fed0b> vcard:hasURL \"https://bluehub.jrc.ec.europa.eu/erddap/griddap/noaa_pfeg_d543_8870_bc7f.html\" ;\n",
      "    owl:a bibo:WebPage .\n",
      "\n",
      "<urn:uuid:3dcf30fc-1a7b-4af9-86cf-ca2c45ac6af6> dc:hasType \"theme\" ;\n",
      "    dc:partOf \"CF Standard Name Table v27\" ;\n",
      "    bcube:hasValue \"latitude\",\n",
      "        \"longitude\",\n",
      "        \"time\" ;\n",
      "    owl:a bcube:thesaurusSubset .\n",
      "\n",
      "<urn:uuid:3fde314c-bae5-4985-a04f-f6ff95dee4a0> vcard:hasURL \"https://bluehub.jrc.ec.europa.eu/erddap/wms/noaa_pfeg_d543_8870_bc7f/request\" ;\n",
      "    owl:a bibo:WebPage .\n",
      "\n",
      "<urn:uuid:78742f73-6d77-483b-aca3-80059dda8233> dc:location \"Ispra, VA, Italy\" ;\n",
      "    owl:a dcat:publisher ;\n",
      "    foaf:name \"ERDDAP, version 1.60, at Maritime Affairs Unit of the Joint Research Centre\" .\n",
      "\n",
      "<urn:uuid:d3790ec1-2d11-4230-9097-6479a7efc8f3> dc:hasType \"theme\" ;\n",
      "    dc:partOf \"Uncontrolled\" ;\n",
      "    bcube:hasValue \"conversion\",\n",
      "        \"data\",\n",
      "        \"fnmoc\",\n",
      "        \"level\",\n",
      "        \"mean\",\n",
      "        \"navg\",\n",
      "        \"observed\",\n",
      "        \"pressure\",\n",
      "        \"sea\",\n",
      "        \"theortically\",\n",
      "        \"value\" ;\n",
      "    owl:a bcube:thesaurusSubset .\n",
      "\n",
      "<urn:uuid:f96b1d17-5cf6-4aa8-a4dc-dcc9ed2a3f7e> vcard:hasURL \"https://bluehub.jrc.ec.europa.eu/erddap/griddap/noaa_pfeg_d543_8870_bc7f.graph\" ;\n",
      "    owl:a bibo:WebPage .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's play with triples\n",
    "\n",
    "import rdflib\n",
    "import hashlib\n",
    "from uuid import uuid4\n",
    "from rdflib import Graph, Literal, RDF, RDFS, Namespace, URIRef\n",
    "from rdflib.namespace import DC, DCTERMS, FOAF, XSD, OWL\n",
    "\n",
    "\n",
    "class Grapher():\n",
    "    def __init__(self):\n",
    "        self.graph = Graph()\n",
    "        self._bind_namespaces()\n",
    "    \n",
    "    # some faked namespaces\n",
    "    _ontology_uris = {\n",
    "        'bcube': 'http://purl.org/nsidc/bcube/bcube#',\n",
    "        'vcard': 'http://purl.org/nsidc/bcube/vcard#',\n",
    "        'esip': 'http://purl.org/nsidc/bcube/esip#',\n",
    "        'vivo': 'http://purl.org/nsidc/bcube/vivo#',\n",
    "        'bibo': 'http://purl.org/nsidc/bcube/bibo#',\n",
    "        'GeoSPARQL': 'http://purl.org/nsidc/bcube/geosparql#',\n",
    "        'dcat': 'http://purl.org/nsidc/bcube/dcat#',\n",
    "        'dc': str(DC),\n",
    "        'dct': str(DCTERMS),\n",
    "        'foaf': str(FOAF),\n",
    "        'xsd': str(XSD),\n",
    "        'owl': str(OWL)\n",
    "    }\n",
    "    \n",
    "    def _bind_namespaces(self):\n",
    "        # bind our lovely fake namespaces\n",
    "        for prefix, uri in self._ontology_uris.iteritems():\n",
    "            self.graph.bind(prefix, uri)\n",
    "\n",
    "    def generate_predicate(self, prefix, name):\n",
    "        return Namespace(self._ontology_uris[prefix])[name]\n",
    "            \n",
    "    def create_resource(self, resource_prefix, resource_type, identifier=''):\n",
    "        # make a thing with a uuid as a urn\n",
    "        # and just assign it to type if it's not overridden\n",
    "        identifier = identifier if identifier else uuid4().urn\n",
    "        resource = self.graph.resource(identifier)\n",
    "        ref = Namespace(self._ontology_uris[resource_prefix])[resource_type]\n",
    "        resource.add(OWL.a, URIRef(ref))\n",
    "        return resource\n",
    "\n",
    "    def serialize(self):\n",
    "        return self.graph.serialize(format='turtle')\n",
    "    \n",
    "    def graphalize(self, doc):\n",
    "        # not a word\n",
    "        # so from our json.\n",
    "        # which is currently incorrect in the relate\n",
    "        # between the catalog record and the dataset (no primaryTopic ref)\n",
    "\n",
    "        for root_entity_type, root_entity in doc.iteritems():\n",
    "            if root_entity_type == 'catalog_record':\n",
    "                catalog_record = self.create_resource('dcat', 'CatalogRecord', 'urn:sha:21a2c32fd74798563eed88a3fcd1acf38092f47e')\n",
    "                catalog_record.add(self.generate_predicate('vcard', 'hasURL'), Literal(root_entity['url']))\n",
    "                catalog_record.add(self.generate_predicate('vivo', 'harvestDate'), Literal(root_entity['harvestDate']))\n",
    "                catalog_record.add(DC.conformsTo, Literal(root_entity['conformsTo']))\n",
    "            elif root_entity_type == 'dataset':\n",
    "                dataset = self.create_resource('dcat', 'Dataset', 'urn:sha:e018c0a1fb2f9fdc497f7f78eede802c833883ef')\n",
    "\n",
    "                dataset.add(DCTERMS.identifier, Literal(root_entity['identifier']))\n",
    "                dataset.add(DCTERMS.title, Literal(root_entity['title']))\n",
    "                dataset.add(DC.description, Literal(root_entity['abstract']))\n",
    "\n",
    "                if 'publisher' in root_entity:\n",
    "                    publisher = self.create_resource('dcat', 'publisher')\n",
    "                    publisher.add(DC.location, Literal(root_entity['publisher']['location']))\n",
    "                    publisher.add(FOAF.name, Literal(root_entity['publisher']['name']))\n",
    "                    dataset.add(self.generate_predicate('dcat', 'publisher'), publisher)\n",
    "\n",
    "                for keywords in root_entity.get('keywords', []):\n",
    "                    keyset = self.create_resource('bcube', 'thesaurusSubset')\n",
    "                    if 'type' in keywords:\n",
    "                        keyset.add(DC.hasType, Literal(keywords['type']))\n",
    "                    if 'thesaurus' in keywords:\n",
    "                        keyset.add(DC.partOf, Literal(keywords['thesaurus']))\n",
    "\n",
    "                    for term in keywords['terms']:\n",
    "                        keyset.add(self.generate_predicate('bcube', 'hasValue'), Literal(term))\n",
    "\n",
    "                    dataset.add(DC.conformsTo, keyset)\n",
    "\n",
    "                if 'temporal_extent' in root_entity:\n",
    "                    # NOTE: these are not ISO 8601 obv.\n",
    "                    begdate = root_entity['temporal_extent'].get('startDate')\n",
    "                    enddate = root_entity['temporal_extent'].get('edDate')\n",
    "\n",
    "                    dataset.add(self.generate_predicate('esip', 'startDate'), Literal(begdate))\n",
    "                    dataset.add(self.generate_predicate('esip', 'endDate'), Literal(enddate))\n",
    "\n",
    "                if 'spatial_extent' in root_entity:\n",
    "                    dataset.add(DC.spatial, Literal(root_entity['spatial_extent']['wkt']))\n",
    "\n",
    "                    dataset.add(self.generate_predicate('esip', 'westBound'),\n",
    "                                Literal(root_entity['spatial_extent']['west']))\n",
    "\n",
    "                    dataset.add(self.generate_predicate('esip', 'eastBound'),\n",
    "                                Literal(root_entity['spatial_extent']['east']))\n",
    "\n",
    "                    dataset.add(self.generate_predicate('esip', 'southBound'),\n",
    "                                Literal(root_entity['spatial_extent']['south']))\n",
    "\n",
    "                    dataset.add(self.generate_predicate('esip', 'northBound'),\n",
    "                                Literal(root_entity['spatial_extent']['north']))\n",
    "\n",
    "                for webpage in root_entity.get('webpages', []):\n",
    "                    relation = self.create_resource('bibo', 'WebPage')\n",
    "                    relation.add(self.generate_predicate('vcard', 'hasURL'), Literal(webpage['url']))\n",
    "                    dataset.add(DC.relation, relation)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "grapher = Grapher()    \n",
    "grapher.graphalize(description)\n",
    "print grapher.serialize()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generating local graphs for any fgdc response\n",
    "\n",
    "i would note that we are not catching every fgdc through the identifier - not quite valid/complete responses are being dropped. this generates roughly three thousand graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# so let's make a new temp class for the harvest + parser parts\n",
    "# and this is not what we really want to do. probably.\n",
    "\n",
    "class Fgdc():\n",
    "    def __init__(self, doc):\n",
    "        self.url = doc.get('source_url', '')\n",
    "        self.response = self._prep_response(doc.get('content', ''))\n",
    "        self.harvested = doc.get('tstamp', '')  # except i did not carry this through in the clean task\n",
    "        self._prep_parser()\n",
    "        \n",
    "    def _prep_parser(self):\n",
    "        parser = Parser(self.response)\n",
    "        self.reader = FgdcItemReader(parser.xml)\n",
    "    \n",
    "    def _prep_response(self, response):\n",
    "        # this shouldn't be necessary but cargo-culting here is fine by me.\n",
    "        response = response.replace('\\\\\\n', '').replace('\\r\\n', '').replace('\\\\r', '').replace('\\\\n', '').replace('\\n', '')\n",
    "        return response.decode('utf-8', errors='replace').encode('unicode_escape') \n",
    "        \n",
    "    def parse(self):\n",
    "        description = self.reader.parse_item()\n",
    "        \n",
    "        # note: this is still very very wrong\n",
    "        description['catalog_record']['url'] = self.url\n",
    "        description['catalog_record']['harvestDate'] = self.harvested\n",
    "        \n",
    "        return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "identified_dir = '/Users/sscott/Documents/tmp/identified/'\n",
    "triples_dir = '/Users/sscott/Documents/tmp/triples/'\n",
    "\n",
    "with open('data/small_harvest_fgdc_as_md5.csv', 'rb') as csvfile:\n",
    "    cr = csv.DictReader(csvfile, delimiter=\"|\")\n",
    "\n",
    "    for row in cr:\n",
    "        url = row['source_url'].strip()\n",
    "        md5 = row['raw_content_md5'].strip()\n",
    "        \n",
    "        # go open the cleaned up version by md5\n",
    "        filepath = os.path.join(identified_dir, md5 + '_identified.json')\n",
    "        if not os.path.exists(filepath):\n",
    "            continue\n",
    "        \n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.loads(f.read())\n",
    "            \n",
    "        fgdc = Fgdc(data)\n",
    "        description = fgdc.parse()\n",
    "        \n",
    "        grapher = Grapher()\n",
    "        grapher.graphalize(description)\n",
    "        ttl = grapher.serialize()\n",
    "        \n",
    "        with open(os.path.join(triples_dir, md5 + '.ttl'), 'w') as f:\n",
    "            f.write(ttl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
