{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quick checks of the new fgdc triples structure\n",
    "and maybe the triples (yes the triples, whatevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from semproc.parser import Parser\n",
    "from semproc.preprocessors.metadata_preprocessors import FgdcItemReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the proto-triples example\n",
    "with open('../response_examples/fgdc_proto_example_1.xml', 'r') as f:\n",
    "    response = f.read()\n",
    "\n",
    "# this shouldn't be necessary but cargo-culting here is fine by me.\n",
    "response = response.replace('\\\\\\n', '').replace('\\r\\n', '').replace('\\\\r', '').replace('\\\\n', '').replace('\\n', '')\n",
    "response = response.decode('utf-8', errors='replace').encode('unicode_escape') \n",
    "    \n",
    "url = 'https://bluehub.jrc.ec.europa.eu/erddap/metadata/fgdc/xml/noaa_pfeg_d543_8870_bc7f_fgdc.xml'\n",
    "identities = [\n",
    "    {\"protocol\": \"FGDC\", \n",
    "     \"metadata\": {\n",
    "            \"version\": [\"FGDC Content Standards for Digital Geospatial Metadata, FGDC-STD-001-1998\"], \n",
    "            \"name\": \"FGDC\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "parser = Parser(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# execute the parse (this one takes xml)\n",
    "reader = FgdcItemReader(parser.xml, url, '2015-06-20T20:22:00.643Z')\n",
    "description = reader.parse_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'catalog_record': {'conformsTo': 'http://www.ngdc.noaa.gov/metadata/published/xsd/ngdcSchema/schema.xsd',\n",
       "  'harvestDate': '2015-06-20T20:22:00.643Z',\n",
       "  'object_id': 'urn:sha:f65fb3d1efeee860adbbb53d3a20e80e1f50fe625e4887155f196a92',\n",
       "  'relationships': [{'object_id': 'urn:sha:d5a3a66150264cfeca19322b996a1cbf202b15966e0f1e41b99ae991',\n",
       "    'relate': 'primaryTopic'}],\n",
       "  'url': 'https://bluehub.jrc.ec.europa.eu/erddap/metadata/fgdc/xml/noaa_pfeg_d543_8870_bc7f_fgdc.xml'},\n",
       " 'dataset': {'abstract': 'Navy Global Environmental Model (NAVGEM) is a global numerical weather prediction computer model. It replaced NOGAPS as the prime model in the middle of February 2013 at the Navy Fleet Numerical Meteorology and Oceanography Center (FNMOC) Weather model synoptic site. [Wikipedia]',\n",
       "  'identifier': 'https://bluehub.jrc.ec.europa.eu:noaa_pfeg_d543_8870_bc7f',\n",
       "  'object_id': 'urn:sha:d5a3a66150264cfeca19322b996a1cbf202b15966e0f1e41b99ae991',\n",
       "  'relationships': [{'object_id': 'urn:sha:f65fb3d1efeee860adbbb53d3a20e80e1f50fe625e4887155f196a92',\n",
       "    'relate': 'description'},\n",
       "   {'object_id': 'urn:uuid:ea5dd3b5-1299-483a-a473-033a2f9776de',\n",
       "    'relate': 'publisher'},\n",
       "   {'object_id': 'urn:sha:c8e6a320278b006f2f7b6b293fcab0331b77b84cfd63b47408537e85',\n",
       "    'relate': 'relation'},\n",
       "   {'object_id': 'urn:sha:be86d663bf9cb281de03aff9ae3fa51c6728075d344e55ca3a376514',\n",
       "    'relate': 'relation'},\n",
       "   {'object_id': 'urn:sha:8df1983f1f9573be5059558fd20d718d9550720c873eb8930cdc6735',\n",
       "    'relate': 'relation'},\n",
       "   {'object_id': 'urn:uuid:13ac506a-053b-49af-b053-0584746cf2a5',\n",
       "    'relate': 'conformsTo'},\n",
       "   {'object_id': 'urn:uuid:892fff88-fbea-48a3-a318-cb99840b9fd7',\n",
       "    'relate': 'conformsTo'}],\n",
       "  'spatial_extent': {'east': '180.0',\n",
       "   'north': '90.0',\n",
       "   'south': '-90.0',\n",
       "   'west': '-180.0',\n",
       "   'wkt': 'POLYGON ((-180 -90,-180 90,180 90,180 -90,-180 -90))'},\n",
       "  'temporal_extent': {'endDate': '2014-08-13T00:00:00',\n",
       "   'startDate': '2013-02-15T00:00:00'},\n",
       "  'title': 'Navy Global Environmental Model (NAVGEM), 0.5 degree, Pressure MSL'},\n",
       " 'keywords': [{'object_id': 'urn:uuid:13ac506a-053b-49af-b053-0584746cf2a5',\n",
       "   'terms': ['conversion',\n",
       "    'data',\n",
       "    'fnmoc',\n",
       "    'level',\n",
       "    'mean',\n",
       "    'navg',\n",
       "    'observed',\n",
       "    'pressure',\n",
       "    'sea',\n",
       "    'theortically',\n",
       "    'value'],\n",
       "   'thesaurus': 'Uncontrolled',\n",
       "   'type': 'theme'},\n",
       "  {'object_id': 'urn:uuid:892fff88-fbea-48a3-a318-cb99840b9fd7',\n",
       "   'terms': ['time', 'latitude', 'longitude'],\n",
       "   'thesaurus': 'CF Standard Name Table v27',\n",
       "   'type': 'theme'}],\n",
       " 'publisher': {'location': 'Ispra, VA, Italy',\n",
       "  'name': 'ERDDAP, version 1.60, at Maritime Affairs Unit of the Joint Research Centre',\n",
       "  'object_id': 'urn:uuid:ea5dd3b5-1299-483a-a473-033a2f9776de'},\n",
       " 'webpages': [{'object_id': 'urn:sha:c8e6a320278b006f2f7b6b293fcab0331b77b84cfd63b47408537e85',\n",
       "   'url': 'https://bluehub.jrc.ec.europa.eu/erddap/griddap/noaa_pfeg_d543_8870_bc7f.html'},\n",
       "  {'object_id': 'urn:sha:be86d663bf9cb281de03aff9ae3fa51c6728075d344e55ca3a376514',\n",
       "   'url': 'https://bluehub.jrc.ec.europa.eu/erddap/griddap/noaa_pfeg_d543_8870_bc7f.graph'},\n",
       "  {'object_id': 'urn:sha:8df1983f1f9573be5059558fd20d718d9550720c873eb8930cdc6735',\n",
       "   'url': 'https://bluehub.jrc.ec.europa.eu/erddap/wms/noaa_pfeg_d543_8870_bc7f/request'}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a minorly faked description dict (for the triples)\n",
    "\n",
    "description_x = {\n",
    "    \"catalog_record\": {\n",
    "        \"object_id\": \"urn:sha:0139cbf453d618963bed0a2f256d1234\",\n",
    "        \"conformsTo\": \"http://www.ngdc.noaa.gov/metadata/published/xsd/ngdcSchema/schema.xsd\",\n",
    "        \"harvestDate\": \"2015-06-20T20:22:00.643Z\",\n",
    "        \"url\": \"https://bluehub.jrc.ec.europa.eu/erddap/metadata/fgdc/xml/noaa_pfeg_d543_8870_bc7f_fgdc.xml\",\n",
    "        \"sha\": \"0139cbf453d618963bed0a2f256d1234\",\n",
    "        \"relationships\": [\n",
    "            {\"relate\": \"primaryTopic\", \"object_id\": \"urn:sha:e018c0a1fb2f9fdc497f7f78eede802c833883ef\"}\n",
    "        ]\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"object_id\": \"urn:sha:e018c0a1fb2f9fdc497f7f78eede802c833883ef\", \n",
    "        \"abstract\": \"Navy Global Environmental Model (NAVGEM) is a global numerical weather prediction computer model. It replaced NOGAPS as the prime model in the middle of February 2013 at the Navy Fleet Numerical Meteorology and Oceanography Center (FNMOC) Weather model synoptic site. [Wikipedia]\",\n",
    "        \"identifier\": \"https://bluehub.jrc.ec.europa.eu:noaa_pfeg_d543_8870_bc7f\",\n",
    "        \"spatial_extent\": {\n",
    "            \"east\": \"180.0\",\n",
    "            \"north\": \"90.0\",\n",
    "            \"south\": \"-90.0\",\n",
    "            \"west\": \"-180.0\",\n",
    "            \"wkt\": \"POLYGON ((-180 -90,-180 90,180 90,180 -90,-180 -90))\"\n",
    "        },\n",
    "        \"title\": \"Navy Global Environmental Model (NAVGEM), 0.5 degree, Pressure MSL\",\n",
    "        \"temporal_extent\": {\n",
    "            \"endDate\": \"20140813\",\n",
    "            \"startDate\": \"20130215\"\n",
    "        },        \n",
    "        \"relationships\": [\n",
    "            {\"relate\": \"description\", \"object_id\": \"urn:sha:0139cbf453d618963bed0a2f256d1234\"},\n",
    "            {\"relate\": \"publisher\", \"object_id\": \"urn:sha:c19adcbe-210a-11e5-b5f7-727283247c7f\"},\n",
    "            {\"relate\": \"conformsTo\", \"object_id\": \"urn:sha:83e3c699fb9fa6e365214fb62b2b89e0f23e401f\"},\n",
    "            {\"relate\": \"conformsTo\", \"object_id\": \"urn:sha:ae07655a5ccea0e2a1a2b99c22ab2e7667607cae\"},\n",
    "            {\"relate\": \"relation\", \"object_id\": \"urn:sha:7948076b6f793f814ecfedf125bb1bdf2278f148\"},\n",
    "            {\"relate\": \"relation\", \"object_id\": \"urn:sha:e829d4c2b52aa8a126f9a83c7b8fca80e15a9f54\"},\n",
    "            {\"relate\": \"relation\", \"object_id\": \"urn:sha:1285c67aa5d8563be9efa099068395ebe98f1d85\"}\n",
    "        ]\n",
    "    },\n",
    "    \"publisher\": {\n",
    "        \"object_id\": \"urn:sha:c19adcbe-210a-11e5-b5f7-727283247c7f\",\n",
    "        \"location\": \"Ispra, VA, Italy\",\n",
    "        \"name\": \"ERDDAP, version 1.60, at Maritime Affairs Unit of the Joint Research Centre\"\n",
    "    },\n",
    "    \"keywords\": [\n",
    "        {\n",
    "            \"object_id\": \"urn:sha:83e3c699fb9fa6e365214fb62b2b89e0f23e401f\",\n",
    "            \"terms\": [\n",
    "                \"conversion\",\n",
    "                \"data\",\n",
    "                \"fnmoc\",\n",
    "                \"level\",\n",
    "                \"mean\",\n",
    "                \"navg\",\n",
    "                \"observed\",\n",
    "                \"pressure\",\n",
    "                \"sea\",\n",
    "                \"theortically\",\n",
    "                \"value\"\n",
    "            ],\n",
    "            \"thesaurus\": \"Uncontrolled\",\n",
    "            \"type\": \"theme\"\n",
    "        },\n",
    "        {\n",
    "            \"object_id\": \"urn:sha:ae07655a5ccea0e2a1a2b99c22ab2e7667607cae\",\n",
    "            \"terms\": [\n",
    "                \"time\",\n",
    "                \"latitude\",\n",
    "                \"longitude\"\n",
    "            ],\n",
    "            \"thesaurus\": \"CF Standard Name Table v27\",\n",
    "            \"type\": \"theme\"\n",
    "        }\n",
    "    ],\n",
    "    \"webpages\": [\n",
    "        {\n",
    "            \"object_id\": \"urn:sha:7948076b6f793f814ecfedf125bb1bdf2278f148\",\n",
    "            \"url\": \"https://bluehub.jrc.ec.europa.eu/erddap/griddap/noaa_pfeg_d543_8870_bc7f.html\"\n",
    "        },\n",
    "        {\n",
    "            \"object_id\": \"urn:sha:e829d4c2b52aa8a126f9a83c7b8fca80e15a9f54\",\n",
    "            \"url\": \"https://bluehub.jrc.ec.europa.eu/erddap/griddap/noaa_pfeg_d543_8870_bc7f.graph\"\n",
    "        },\n",
    "        {\n",
    "            \"object_id\": \"urn:sha:1285c67aa5d8563be9efa099068395ebe98f1d85\",\n",
    "            \"url\": \"https://bluehub.jrc.ec.europa.eu/erddap/wms/noaa_pfeg_d543_8870_bc7f/request\"\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix bcube: <http://purl.org/BCube/#> .\n",
      "@prefix bibo: <http://purl.org/ontology/bibo/#> .\n",
      "@prefix dc: <http://purl.org/dc/elements/1.1/> .\n",
      "@prefix dcat: <http://www.w3.org/TR/vocab-dcat/#> .\n",
      "@prefix dct: <http://purl.org/dc/terms/> .\n",
      "@prefix esip: <http://purl.org/esip/#> .\n",
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
      "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix vcard: <http://www.w3.org/TR/vcard-rdf/#> .\n",
      "@prefix vivo: <http://vivo.ufl.edu/ontology/vivo-ufl/#> .\n",
      "@prefix xml: <http://www.w3.org/XML/1998/namespace> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "<urn:sha:8df1983f1f9573be5059558fd20d718d9550720c873eb8930cdc6735> owl:a bibo:WebPage ;\n",
      "    vcard:hasURL \"https://bluehub.jrc.ec.europa.eu/erddap/wms/noaa_pfeg_d543_8870_bc7f/request\" .\n",
      "\n",
      "<urn:sha:be86d663bf9cb281de03aff9ae3fa51c6728075d344e55ca3a376514> owl:a bibo:WebPage ;\n",
      "    vcard:hasURL \"https://bluehub.jrc.ec.europa.eu/erddap/griddap/noaa_pfeg_d543_8870_bc7f.graph\" .\n",
      "\n",
      "<urn:sha:c8e6a320278b006f2f7b6b293fcab0331b77b84cfd63b47408537e85> owl:a bibo:WebPage ;\n",
      "    vcard:hasURL \"https://bluehub.jrc.ec.europa.eu/erddap/griddap/noaa_pfeg_d543_8870_bc7f.html\" .\n",
      "\n",
      "<urn:sha:d5a3a66150264cfeca19322b996a1cbf202b15966e0f1e41b99ae991> dc:conformsTo <urn:uuid:13ac506a-053b-49af-b053-0584746cf2a5>,\n",
      "        <urn:uuid:892fff88-fbea-48a3-a318-cb99840b9fd7> ;\n",
      "    dc:description <urn:sha:f65fb3d1efeee860adbbb53d3a20e80e1f50fe625e4887155f196a92>,\n",
      "        \"Navy Global Environmental Model (NAVGEM) is a global numerical weather prediction computer model. It replaced NOGAPS as the prime model in the middle of February 2013 at the Navy Fleet Numerical Meteorology and Oceanography Center (FNMOC) Weather model synoptic site. [Wikipedia]\" ;\n",
      "    dc:relation <urn:sha:8df1983f1f9573be5059558fd20d718d9550720c873eb8930cdc6735>,\n",
      "        <urn:sha:be86d663bf9cb281de03aff9ae3fa51c6728075d344e55ca3a376514>,\n",
      "        <urn:sha:c8e6a320278b006f2f7b6b293fcab0331b77b84cfd63b47408537e85> ;\n",
      "    dc:spatial \"POLYGON ((-180 -90,-180 90,180 90,180 -90,-180 -90))\" ;\n",
      "    dct:identifier \"https://bluehub.jrc.ec.europa.eu:noaa_pfeg_d543_8870_bc7f\" ;\n",
      "    dct:title \"Navy Global Environmental Model (NAVGEM), 0.5 degree, Pressure MSL\" ;\n",
      "    esip:eastBound \"180.0\" ;\n",
      "    esip:endDate \"None\" ;\n",
      "    esip:northBound \"90.0\" ;\n",
      "    esip:southBound \"-90.0\" ;\n",
      "    esip:startDate \"2013-02-15T00:00:00\" ;\n",
      "    esip:westBound \"-180.0\" ;\n",
      "    owl:a dcat:Dataset ;\n",
      "    dcat:publisher <urn:uuid:ea5dd3b5-1299-483a-a473-033a2f9776de> .\n",
      "\n",
      "<urn:sha:f65fb3d1efeee860adbbb53d3a20e80e1f50fe625e4887155f196a92> dc:conformsTo \"http://www.ngdc.noaa.gov/metadata/published/xsd/ngdcSchema/schema.xsd\" ;\n",
      "    vivo:harvestDate \"2015-06-20T20:22:00.643Z\" ;\n",
      "    owl:a dcat:CatalogRecord ;\n",
      "    vcard:hasURL \"https://bluehub.jrc.ec.europa.eu/erddap/metadata/fgdc/xml/noaa_pfeg_d543_8870_bc7f_fgdc.xml\" ;\n",
      "    foaf:primaryTopic <urn:sha:d5a3a66150264cfeca19322b996a1cbf202b15966e0f1e41b99ae991> .\n",
      "\n",
      "<urn:uuid:13ac506a-053b-49af-b053-0584746cf2a5> bcube:hasValue \"conversion\",\n",
      "        \"data\",\n",
      "        \"fnmoc\",\n",
      "        \"level\",\n",
      "        \"mean\",\n",
      "        \"navg\",\n",
      "        \"observed\",\n",
      "        \"pressure\",\n",
      "        \"sea\",\n",
      "        \"theortically\",\n",
      "        \"value\" ;\n",
      "    dc:hasType \"theme\" ;\n",
      "    dc:partOf \"Uncontrolled\" ;\n",
      "    owl:a bcube:thesaurusSubset .\n",
      "\n",
      "<urn:uuid:892fff88-fbea-48a3-a318-cb99840b9fd7> bcube:hasValue \"latitude\",\n",
      "        \"longitude\",\n",
      "        \"time\" ;\n",
      "    dc:hasType \"theme\" ;\n",
      "    dc:partOf \"CF Standard Name Table v27\" ;\n",
      "    owl:a bcube:thesaurusSubset .\n",
      "\n",
      "<urn:uuid:ea5dd3b5-1299-483a-a473-033a2f9776de> dc:location \"Ispra, VA, Italy\" ;\n",
      "    owl:a dcat:publisher ;\n",
      "    foaf:name \"ERDDAP, version 1.60, at Maritime Affairs Unit of the Joint Research Centre\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's play with triples\n",
    "\n",
    "import rdflib\n",
    "import hashlib\n",
    "from uuid import uuid4\n",
    "from rdflib import Graph, Literal, RDF, RDFS, Namespace, URIRef\n",
    "from rdflib.namespace import DC, DCTERMS, FOAF, XSD, OWL\n",
    "\n",
    "\n",
    "class Grapher():\n",
    "    def __init__(self):\n",
    "        self.graph = Graph()\n",
    "        self._bind_namespaces()\n",
    "    \n",
    "    # some faked namespaces\n",
    "    _ontology_uris = {\n",
    "        'bcube': 'http://purl.org/BCube/#',\n",
    "        'vcard': 'http://www.w3.org/TR/vcard-rdf/#',\n",
    "        'esip': 'http://purl.org/esip/#',\n",
    "        'vivo': 'http://vivo.ufl.edu/ontology/vivo-ufl/#',\n",
    "        'bibo': 'http://purl.org/ontology/bibo/#',\n",
    "        'dcat': 'http://www.w3.org/TR/vocab-dcat/#',\n",
    "        'dc': str(DC),\n",
    "        'dct': str(DCTERMS),\n",
    "        'foaf': str(FOAF),\n",
    "        'xsd': str(XSD),\n",
    "        'owl': str(OWL)\n",
    "    }\n",
    "    \n",
    "    def _bind_namespaces(self):\n",
    "        # bind our lovely fake namespaces\n",
    "        for prefix, uri in self._ontology_uris.iteritems():\n",
    "            self.graph.bind(prefix, uri)\n",
    "\n",
    "    def generate_predicate(self, prefix, name):\n",
    "        return Namespace(self._ontology_uris[prefix])[name]\n",
    "\n",
    "    def identify_prefix(self, predicate):\n",
    "        # this is, granted, a lesson in technical debt.\n",
    "        debt = {\n",
    "            \"dc\": [\"description\", \"conformsTo\", \"relation\"],\n",
    "            \"dcat\": [\"publisher\"],\n",
    "            \"foaf\": [\"primaryTopic\"]\n",
    "        }\n",
    "        \n",
    "        for k, v in debt.iteritems():\n",
    "            if predicate in v:\n",
    "                return k\n",
    "        return ''\n",
    "            \n",
    "    def create_resource(self, resource_prefix, resource_type, identifier=''):\n",
    "        # make a thing with a uuid as a urn\n",
    "        # and just assign it to type if it's not overridden\n",
    "        identifier = identifier if identifier else uuid4().urn\n",
    "        resource = self.graph.resource(identifier)\n",
    "        ref = Namespace(self._ontology_uris[resource_prefix])[resource_type]\n",
    "        resource.add(OWL.a, URIRef(ref))\n",
    "        return resource\n",
    "\n",
    "    def _process_catalog(self, entity):\n",
    "        catalog_record = self.create_resource('dcat', 'CatalogRecord', entity['object_id'])\n",
    "        catalog_record.add(self.generate_predicate('vcard', 'hasURL'), Literal(entity['url']))\n",
    "        catalog_record.add(self.generate_predicate('vivo', 'harvestDate'), Literal(entity['harvestDate']))\n",
    "        catalog_record.add(DC.conformsTo, Literal(entity['conformsTo']))\n",
    "        \n",
    "        for relationship in entity['relationships']:\n",
    "            # so. current object, verb, id of object, existence unknown\n",
    "            self.relates.append((catalog_record, relationship['relate'], relationship['object_id']))\n",
    "            \n",
    "    def _process_dataset(self, entity):\n",
    "        dataset = self.create_resource('dcat', 'Dataset', entity['object_id'])\n",
    "        dataset.add(DCTERMS.identifier, Literal(entity['identifier']))\n",
    "        dataset.add(DCTERMS.title, Literal(entity['title']))\n",
    "        dataset.add(DC.description, Literal(entity['abstract']))\n",
    "        \n",
    "        if 'temporal_extent' in entity:\n",
    "            # NOTE: these are not ISO 8601 obv.\n",
    "            begdate = entity['temporal_extent'].get('startDate')\n",
    "            enddate = entity['temporal_extent'].get('edDate')\n",
    "\n",
    "            dataset.add(self.generate_predicate('esip', 'startDate'), Literal(begdate))\n",
    "            dataset.add(self.generate_predicate('esip', 'endDate'), Literal(enddate))\n",
    "\n",
    "        if 'spatial_extent' in entity:\n",
    "            dataset.add(DC.spatial, Literal(entity['spatial_extent']['wkt']))\n",
    "\n",
    "            dataset.add(self.generate_predicate('esip', 'westBound'),\n",
    "                        Literal(entity['spatial_extent']['west']))\n",
    "\n",
    "            dataset.add(self.generate_predicate('esip', 'eastBound'),\n",
    "                        Literal(entity['spatial_extent']['east']))\n",
    "\n",
    "            dataset.add(self.generate_predicate('esip', 'southBound'),\n",
    "                        Literal(entity['spatial_extent']['south']))\n",
    "\n",
    "            dataset.add(self.generate_predicate('esip', 'northBound'),\n",
    "                        Literal(entity['spatial_extent']['north']))\n",
    "        \n",
    "        for relationship in entity['relationships']:\n",
    "            self.relates.append((dataset, relationship['relate'], relationship['object_id']))\n",
    "        \n",
    "    def _process_keywords(self, entity):\n",
    "        for keywords in entity:\n",
    "            keyset = self.create_resource('bcube', 'thesaurusSubset', keywords['object_id'])\n",
    "            if 'type' in keywords:\n",
    "                keyset.add(DC.hasType, Literal(keywords['type']))\n",
    "            if 'thesaurus' in keywords:\n",
    "                keyset.add(DC.partOf, Literal(keywords['thesaurus']))\n",
    "\n",
    "            for term in keywords['terms']:\n",
    "                keyset.add(self.generate_predicate('bcube', 'hasValue'), Literal(term))\n",
    "        \n",
    "    def _process_publisher(self, entity):\n",
    "        publisher = self.create_resource('dcat', 'publisher', entity['object_id'])\n",
    "        publisher.add(DC.location, Literal(entity['location']))\n",
    "        publisher.add(FOAF.name, Literal(entity['name']))\n",
    "        \n",
    "    def _process_webpages(self, entity):\n",
    "        for webpage in entity:\n",
    "            relation = self.create_resource('bibo', 'WebPage', webpage['object_id'])\n",
    "            relation.add(self.generate_predicate('vcard', 'hasURL'), Literal(webpage['url']))\n",
    "    \n",
    "    def serialize(self):\n",
    "        return self.graph.serialize(format='turtle')\n",
    "    \n",
    "    def graphalize(self, doc):\n",
    "        # not a word\n",
    "        # so from our json.\n",
    "        \n",
    "        # this. is. idk. an ordering thing. i suspect the graph borks\n",
    "        # when you try to add a triple for a non-existent object.\n",
    "        # years of experience. also, i am wrong - it will add anything.\n",
    "        self.relates = []\n",
    "        for entity_type, entity in doc.iteritems():\n",
    "            if entity_type == 'catalog_record':\n",
    "                self._process_catalog(entity)\n",
    "            elif entity_type == 'dataset':\n",
    "                self._process_dataset(entity)\n",
    "            elif entity_type == 'publisher':\n",
    "                self._process_publisher(entity)\n",
    "            elif entity_type == 'keywords':\n",
    "                self._process_keywords(entity)\n",
    "            elif entity_type == 'webpages':\n",
    "                self._process_webpages(entity)\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        for resource, verb, object_id in self.relates:\n",
    "            resource.add(\n",
    "                self.generate_predicate(\n",
    "                    self.identify_prefix(verb), verb),\n",
    "                URIRef(object_id)\n",
    "            )\n",
    "        \n",
    "\n",
    "grapher = Grapher()    \n",
    "grapher.graphalize(description)\n",
    "print grapher.serialize()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generating local graphs for any fgdc response\n",
    "\n",
    "i would note that we are not catching every fgdc through the identifier - not quite valid/complete responses are being dropped. this generates roughly three thousand graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# so let's make a new temp class for the harvest + parser parts\n",
    "# and this is not what we really want to do. probably.\n",
    "\n",
    "class Fgdc():\n",
    "    def __init__(self, doc):\n",
    "        self.url = doc.get('source_url', '')\n",
    "        self.response = self._prep_response(doc.get('content', ''))\n",
    "        self.harvested = doc.get('tstamp', '')  # except i did not carry this through in the clean task\n",
    "        self._prep_parser()\n",
    "        \n",
    "    def _prep_parser(self):\n",
    "        parser = Parser(self.response)\n",
    "        self.reader = FgdcItemReader(parser.xml)\n",
    "    \n",
    "    def _prep_response(self, response):\n",
    "        # this shouldn't be necessary but cargo-culting here is fine by me.\n",
    "        response = response.replace('\\\\\\n', '').replace('\\r\\n', '').replace('\\\\r', '').replace('\\\\n', '').replace('\\n', '')\n",
    "        return response.decode('utf-8', errors='replace').encode('unicode_escape') \n",
    "        \n",
    "    def parse(self):\n",
    "        description = self.reader.parse_item()\n",
    "        \n",
    "        # note: this is still very very wrong\n",
    "        description['catalog_record']['url'] = self.url\n",
    "        description['catalog_record']['harvestDate'] = self.harvested\n",
    "        \n",
    "        return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "identified_dir = '/Users/sscott/Documents/tmp/identified/'\n",
    "triples_dir = '/Users/sscott/Documents/tmp/triples/'\n",
    "\n",
    "with open('data/small_harvest_fgdc_as_md5.csv', 'rb') as csvfile:\n",
    "    cr = csv.DictReader(csvfile, delimiter=\"|\")\n",
    "\n",
    "    for row in cr:\n",
    "        url = row['source_url'].strip()\n",
    "        md5 = row['raw_content_md5'].strip()\n",
    "        \n",
    "        # go open the cleaned up version by md5\n",
    "        filepath = os.path.join(identified_dir, md5 + '_identified.json')\n",
    "        if not os.path.exists(filepath):\n",
    "            continue\n",
    "        \n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.loads(f.read())\n",
    "            \n",
    "        fgdc = Fgdc(data)\n",
    "        description = fgdc.parse()\n",
    "        \n",
    "        grapher = Grapher()\n",
    "        grapher.graphalize(description)\n",
    "        ttl = grapher.serialize()\n",
    "        \n",
    "        with open(os.path.join(triples_dir, md5 + '.ttl'), 'w') as f:\n",
    "            f.write(ttl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
