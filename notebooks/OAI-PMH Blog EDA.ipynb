{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OAI-PMH Blog (http://ekvv.uni-bielefeld.de/blog/baseoai/) has a reasonably well-structured registry of OAI-PMH servers noting things like the framework used, identifier usage, etc. \n",
    "\n",
    "This is some basic parsing and EDA on that registry to get:\n",
    "\n",
    "1. the repository name and URL\n",
    "2. the framework used\n",
    "3. use of dc:identifiers\n",
    "4. changes to the URL (at least to know)\n",
    "5. whether it comes out of OpenDOAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import etree\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import HTMLParser\n",
    "from itertools import chain\n",
    "\n",
    "with open('oaipmh_blog_alle.atom', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "xml = etree.fromstring(text)\n",
    "\n",
    "hparse = HTMLParser.HTMLParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some little xml helpers\n",
    "def generate_localname_xpath(tags):\n",
    "    unchangeds = ['*', '..', '.', '//*']\n",
    "    return '/'.join(\n",
    "        ['%s*[local-name()=\"%s\"]' % ('@' if '@' in t else '', t.replace('@', ''))\n",
    "         if t not in unchangeds else t for t in tags])\n",
    "\n",
    "def extract_attrib(elem, tags):\n",
    "    e = extract_elem(elem, tags)\n",
    "    return e.strip() if e else ''\n",
    "\n",
    "\n",
    "def extract_attribs(elem, tags):\n",
    "    e = extract_elem(elem, tags)\n",
    "    return [m.strip() for m in e]\n",
    "\n",
    "\n",
    "def extract_item(elem, tags):\n",
    "    e = extract_elem(elem, tags)\n",
    "    return e.text.strip() if e is not None and e.text else ''\n",
    "\n",
    "\n",
    "def extract_items(elem, tags):\n",
    "    es = extract_elems(elem, tags)\n",
    "    return [e.text.strip() for e in es if e is not None and e.text]\n",
    "\n",
    "\n",
    "def extract_elems(elem, tags):\n",
    "    xp = generate_localname_xpath(tags)\n",
    "    return elem.xpath(xp)\n",
    "\n",
    "\n",
    "def extract_elem(elem, tags):\n",
    "    xp = generate_localname_xpath(tags)\n",
    "    return next(iter(elem.xpath(xp)), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: not dealing with namespacing at all.\n",
    "\n",
    "entries = xml.xpath('//*/*[local-name()=\"entry\"]')\n",
    "len(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about the patterns for a minute.\n",
    "\n",
    "For the titles:\n",
    "\n",
    "Many things are \"{title of the service} has ...\".\n",
    "\n",
    "New services are marked as \"New OAI-PMH Repository: \".\n",
    "\n",
    "It's not 100% (and why it's clearly a manual blog) that the phrase before \"has\" is only the name of the repository. Nor is it always clear that the \"migrated\" posts refer to a new URL or a new framework. \n",
    "\n",
    "\n",
    "For the text content.\n",
    "\n",
    "For a new link, it's \"the new basicurl is\"; for a new entry, it's \"the basicurl is\" (however, we can get that link from the link/@rel=alternate element).\n",
    "\n",
    "The framework used can be grokked but it also changes patterns often enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oais = []\n",
    "\n",
    "def parse_title(text):\n",
    "    if 'has' in text:\n",
    "        parts = text.strip().split('has')\n",
    "        # let's not call it a triple\n",
    "        return parts[0], parts[1]\n",
    "    elif 'New OAI-PMH ' in text: \n",
    "        return text.replace('New OAI-PMH Repository:', '').strip(), 'new registry'\n",
    "    else:\n",
    "        print '?', text\n",
    "        return text.strip(), ''\n",
    "\n",
    "def parse_content(text):\n",
    "    text = hparse.unescape(text)\n",
    "    soup = BeautifulSoup(text)\n",
    "    lines = soup.text.split('\\n')\n",
    "    \n",
    "    # we can ignore some of the paragraph blocks\n",
    "    # given that we want to know that it's a new link\n",
    "    # and what framework it came from (or moved to)\n",
    "    \n",
    "    info = {}\n",
    "    for line in lines:\n",
    "        if 'repository' in line and 'uses' in line:\n",
    "            info['repo'] = line.strip().split('uses')[-1].strip().replace('.', '')\n",
    "        elif 'repository' in line and 'from' in line and 'to' in line:\n",
    "            info['repo'] = line.strip().split('to')[-1].strip().replace('.', '')\n",
    "            info['repo_changed'] = True\n",
    "        \n",
    "        if 'OpenDOAR' in line:\n",
    "            info['source'] = 'OpenDOAR'\n",
    "        \n",
    "        if 'identifiers' in line:\n",
    "            info['dc:identifiers'] = True\n",
    "    \n",
    "    return info\n",
    "\n",
    "for entry in entries[:2]:\n",
    "    title = entry.xpath('./*[local-name()=\"title\"]/text()')\n",
    "    oai_link = entry.xpath('./*[local-name()=\"link\" and @rel=\"alternate\"]/@href')\n",
    "    \n",
    "    # get the content which will be escaped html\n",
    "    content = entry.xpath('./*[local-name()=\"content\"]/text()')\n",
    "    \n",
    "    name, event = parse_title(title[0])\n",
    "    info = parse_content(content[0])\n",
    "    \n",
    "    oais.append(dict(chain.from_iterable((\n",
    "        {\n",
    "            \"name\": name, \n",
    "            \"link\": oai_link[0],\n",
    "            \"event\": event\n",
    "        }.items(),\n",
    "        info.items()\n",
    "    ))))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': ' been migrated',\n",
       "  'link': 'http://ekvv.uni-bielefeld.de/blog/baseoai/entry/publication_server_of_berlin_brandenburgischen',\n",
       "  'name': 'Publication Server of Berlin-Brandenburgischen Akademie der Wissenschaften, Germany ',\n",
       "  'repo': u'Opus 4 now',\n",
       "  'source': 'OpenDOAR'},\n",
       " {'event': 'new registry',\n",
       "  'link': 'http://ekvv.uni-bielefeld.de/blog/baseoai/entry/new_oai_pmh_repository_dokumentenserver1',\n",
       "  'name': 'Dokumentenserver Klimawandel  of Climate Service Center/HZG , Germany',\n",
       "  'repo': u'Opus 4'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we have a dict of stuff, let's make it pretty and countable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
