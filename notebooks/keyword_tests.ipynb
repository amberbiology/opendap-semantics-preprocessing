{
 "metadata": {
  "name": "",
  "signature": "sha256:c9a6ec372ded4a95c642c5a2cd64bdc7d818a5f19a158825dc95bf9680c82e57"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Keyword Splitting tests\n",
      "\n",
      "See semantics-preprocessing [Issue #8](https://github.com/b-cube/semantics-preprocessing/issues/8)\n",
      "\n",
      "So how do we take some text structure from an unknown, but parsable, metadata source and make it usable by some NLP or other feature characterization method? In some standards, we have a keyword structure that is an implied list (keywords.keyword, etc) but, even within that structure, the free text as \"keyword\" can be some char-delimited list of terms based on the source's metadata generation practices. For example, a keyword text element can be the \">\"-delimited hierarchy of GCMD terms (we can debate the necessity of splitting those structures based on other characterization needs later). \n",
      "\n",
      "In addition, those terms can be phrases so a naive \"split on whitespace\" is an issue.\n",
      "\n",
      "Our test strings as a set of tuples (label, string to test):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keyword_strings = [\n",
      "    (\"Basic comma-delimited singletons\", \"soil, clay, pedon, loam\"),\n",
      "    (\"Basic comma-delimited singletons and phrases\", \"soil, clay, silty clay, silty loam\"),\n",
      "    (\"Whitespace-delimited singletons (DC, OpenSearch)\", \"soil clay pedon loam\"),\n",
      "    (\"GCMD Term List\", \"EARTH SCIENCE > Oceans > Bathymetry/Seafloor Topography > Seafloor Topography\"),\n",
      "    (\"An actual phrase/sentence\", \"Hydrographic Surveys for Selected Locations Within the United States (hydro_bathy_2006)\"),\n",
      "    (\"Pipe-delimited singletons\", \"soil|clay|pedon|loam\")\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The two test strategies - a little regex and a little nltk. The list of potential delimiters: \",\", \";\", \">\", \"|\", \" \", \"+\", \"-\" (this is incomplete, todo: revise for a broad enough set of delims).\n",
      "\n",
      "Let's start with a basic pattern against that set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "simple_pattern = r'[;,|>]*'\n",
      "\n",
      "for label, keywords in keyword_strings:\n",
      "    terms = re.split(simple_pattern, keywords)\n",
      "    \n",
      "    print label, ' => ', keywords\n",
      "    print '\\t', terms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Basic comma-delimited singletons  =>  soil, clay, pedon, loam\n",
        "\t['soil', ' clay', ' pedon', ' loam']\n",
        "Basic comma-delimited singletons and phrases  =>  soil, clay, silty clay, silty loam\n",
        "\t['soil', ' clay', ' silty clay', ' silty loam']\n",
        "Whitespace-delimited singletons (DC, OpenSearch)  =>  soil clay pedon loam\n",
        "\t['soil clay pedon loam']\n",
        "GCMD Term List  =>  EARTH SCIENCE > Oceans > Bathymetry/Seafloor Topography > Seafloor Topography\n",
        "\t['EARTH SCIENCE ', ' Oceans ', ' Bathymetry/Seafloor Topography ', ' Seafloor Topography']\n",
        "An actual phrase/sentence  =>  Hydrographic Surveys for Selected Locations Within the United States (hydro_bathy_2006)\n",
        "\t['Hydrographic Surveys for Selected Locations Within the United States (hydro_bathy_2006)']\n",
        "Pipe-delimited singletons  =>  soil|clay|pedon|loam\n",
        "\t['soil', 'clay', 'pedon', 'loam']\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So far, so good. We aren't handling whitespace well and there are some \"internal\" terms that could be handled (Bathymetry/Seafloor Topography where we have two concepts, Bathymetry Topography and Seafloor Topography. This is a **scoping problem** to be dealt with later). \n",
      "\n",
      "Let's at least handle the trailing whitespaces (bugs me)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for label, keywords in keyword_strings:\n",
      "    terms = [k.strip() for k in re.split(simple_pattern, keywords)]\n",
      "    \n",
      "    print label, ' => ', keywords\n",
      "    print '\\t', terms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Basic comma-delimited singletons  =>  soil, clay, pedon, loam\n",
        "\t['soil', 'clay', 'pedon', 'loam']\n",
        "Basic comma-delimited singletons and phrases  =>  soil, clay, silty clay, silty loam\n",
        "\t['soil', 'clay', 'silty clay', 'silty loam']\n",
        "Whitespace-delimited singletons (DC, OpenSearch)  =>  soil clay pedon loam\n",
        "\t['soil clay pedon loam']\n",
        "GCMD Term List  =>  EARTH SCIENCE > Oceans > Bathymetry/Seafloor Topography > Seafloor Topography\n",
        "\t['EARTH SCIENCE', 'Oceans', 'Bathymetry/Seafloor Topography', 'Seafloor Topography']\n",
        "An actual phrase/sentence  =>  Hydrographic Surveys for Selected Locations Within the United States (hydro_bathy_2006)\n",
        "\t['Hydrographic Surveys for Selected Locations Within the United States (hydro_bathy_2006)']\n",
        "Pipe-delimited singletons  =>  soil|clay|pedon|loam\n",
        "\t['soil', 'clay', 'pedon', 'loam']\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On to some noun chunking and light tokenizing. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from textblob import TextBlob\n",
      "\n",
      "# let's just try on one that we know has a phrase\n",
      "# from the second tuple in keyword_strings\n",
      "txt = TextBlob(\"soil, clay, silty clay, silty loam\")\n",
      "\n",
      "txt.noun_phrases"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "WordList([u'silty clay', u'silty loam'])"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Okay, that was a little unexpected but we can then try to just append the singletons."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "txt.noun_phrases + txt.words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "[u'silty clay',\n",
        " u'silty loam',\n",
        " 'soil',\n",
        " 'clay',\n",
        " 'silty',\n",
        " 'clay',\n",
        " 'silty',\n",
        " 'loam']"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now we have duplicates. Let's try this - extract phrases, remove identified phrases, extract words. (Alternately, use a set at the end.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "set(txt.noun_phrases + txt.words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "{'clay', 'loam', 'silty', u'silty clay', u'silty loam', 'soil'}"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "SET does something we may not want - capturing the words within the phrases. (Note: honestly do not know today if that is important in our larger keyword comparison work, R.)\n",
      "\n",
      "Back to the original thinking."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re \n",
      "substitutions = re.compile('|'.join(txt.noun_phrases))\n",
      "revised_txt = substitutions.sub('', \"soil, clay, silty clay, silty loam\")\n",
      "\n",
      "revised_txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "'soil, clay, , '"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "revised_blob = TextBlob(revised_txt)\n",
      "\n",
      "txt.noun_phrases + revised_blob.words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[u'silty clay', u'silty loam', 'soil', 'clay']"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That got a little ugly there at the end (poor variable management, really). But we now have the list of terms.\n",
      "\n",
      "Up next, what happens across the set of tuples and what do we do about things more closely identified as sentences (our Hydrographic Surveys blob)?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}