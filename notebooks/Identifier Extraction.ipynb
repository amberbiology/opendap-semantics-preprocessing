{
 "metadata": {
  "name": "",
  "signature": "sha256:bdd7212dd87bf971108bd7aa277151e69249b9e372322ac26ecda2d4db4fb585"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "from urls and/or xml text/attributes, can we extract urns? uuids? guids? dois? other ids.\n",
      "\n",
      "starting from a url:\n",
      "\n",
      "1. parse url\n",
      "2. parse route\n",
      "3. parse query params (un-urlencode)\n",
      "4. check route parts\n",
      "\n",
      "\n",
      "starting with xml:\n",
      "\n",
      "1. parse xml\n",
      "2. run the xpath ruleset\n",
      "3. test xpath results if results\n",
      "4. extract all other text\n",
      "5. check text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import glob\n",
      "from lxml import etree\n",
      "import re\n",
      "import os\n",
      "\n",
      "# tuple = type, sample string\n",
      "url_sampleset = [\n",
      "('uuid', 'https://data.noaa.gov/harvest/object/b1b6e62a-cc9b-4cf5-89e5-d280e854eb1c'),\n",
      "('uuid', 'https://data.noaa.gov/harvest/object/2ee5666a-2f9e-4e69-997f-474737fcce71/original'),\n",
      "('urn', 'https://openknowledge.worldbank.org/oai/request?verb=GetRecord&metadataPrefix=oai_dc&identifier=oai:openknowledge.worldbank.org:10986/18612'),\n",
      "('other', 'http://www.ngdc.noaa.gov/metadata/published/NOAA/NESDIS/NGDC/MGG/NOS/H10001-H12000/iso/xml/H10193.xml'),\n",
      "('other', 'https://www.sciencebase.gov/catalog/item/51fc076be4b04b00e3d891e5?format=atom'),\n",
      "('other', 'http://acdisc.gsfc.nasa.gov/opendap/HDF-EOS5/Aura_OMI_Level3/OMSO2e.003/2011/OMI-Aura_L3-OMSO2e_2011m0104_v003-2012m0409t151714.he5.ddx'),\n",
      "('uuid', 'https://www.ngdc.noaa.gov/geoportal/rest/document?id=%7B6FCC9928-1352-44F3-9D7B-BBDC9AF15E9A%7D'),\n",
      "('uuid', 'http://gstore.unm.edu/apps/rgis/datasets/35946660-26d0-4d05-955f-8af7ced2b0c1/metadata/FGDC-STD-001-1998.xml'),\n",
      "('other', 'http://e4ftl01.cr.usgs.gov/MOLT/MOD14.005/2000.04.28/MOD14.A2000119.2335.005.2006261045911.hdf.xml'),\n",
      "('uuid', 'http://portal.oceannet.org/search/full/catalogue/dassh.ac.uk__MEDIN_2.3__CEFAS1abbc9be-1014-45ac-a281-808310790c31.xml/DIF_9.4'),\n",
      "('other', 'http://earth.eo.esa.int/ml3/n412/2005/L3_ENV_MER_N412_m__20050201_GLOB_SI_ESA_9277x9277_-90+90+-180+180_0000.xml'),\n",
      "('other', 'http://www.aauw-ca.org/blog/rss.cfm?mode=full&mode2=cat&catid=9D122695-1617-7A4B-92209B7B1C4B6D75'),\n",
      "('doi', 'http://data.datacite.org/10.14457/KU.THE.2006.802'),\n",
      "('doi', 'http://dx.doi.org/10.4224/20386605'),\n",
      "('doi', 'http://link.springer.com/referenceworkentry/10.1007%2F1-4020-3880-1_85'),\n",
      "('urn', 'http://epsg-registry.org/export.htm?wkt=urn:ogc:def:crs:EPSG::4979'),\n",
      "]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "import urlparse\n",
      "from itertools import chain\n",
      "\n",
      "def unquote(url):\n",
      "    return urllib.unquote(url)\n",
      "\n",
      "def return_path(url, do_split=False):\n",
      "    url = unquote(url)\n",
      "    if do_split:\n",
      "        return urlparse.urlparse(url).path.split('/')\n",
      "    return urlparse.urlparse(url).path\n",
      "\n",
      "def return_parameter_values(url, do_split=False):\n",
      "    url = unquote(url)\n",
      "    parse = urlparse.urlparse(url)\n",
      "    if do_split:\n",
      "        qp = urlparse.parse_qs(parse.query)\n",
      "        return list(chain.from_iterable(qp.values()))\n",
      "    return parse.query\n",
      "    \n",
      "def match(s, p):\n",
      "    m = re.search(p, s)\n",
      "    return m.group(0) if m else ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# extract urn patterns\n",
      "\n",
      "# standalone\n",
      "urn_pattern = re.compile(ur\"^urn:[a-z0-9][a-z0-9-]{0,31}:[a-z0-9()+,\\-.:=@;$_!*'%/?#]+$\", re.IGNORECASE)\n",
      "# in text with punctuation\n",
      "urn_pattern2 = re.compile(ur\"\\burn:[a-z0-9][a-z0-9-]{0,31}:[a-z0-9()+,\\-.:=@;$_!*'%/?#]*[a-z0-9+=@$/]\", re.IGNORECASE)\n",
      "# in text\n",
      "urn_pattern3 = re.compile(ur\"\\burn:[a-z0-9][a-z0-9-]{0,31}:[a-z0-9()+,\\-.:=@;$_!*'%/?#]+\", re.IGNORECASE)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# extract uuid pattern\n",
      "\n",
      "uuid_pattern = re.compile(ur'(\\w{8}(-\\w{4}){3}-\\w{12}?)', re.IGNORECASE)\n",
      "\n",
      "uuid_pattern2 = re.compile(ur'([a-f\\d]{8}(-[a-f\\d]{4}){3}-[a-f\\d]{12}?)', re.IGNORECASE)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# extract doi\n",
      "\n",
      "doi_pattern = re.compile(ur\"\\b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![\\\"&\\\\'])\\\\S)+)\\b\", re.IGNORECASE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use these patterns (so far)\n",
      "pattern_set = [\n",
      "('uuid', re.compile(ur'([a-f\\d]{8}(-[a-f\\d]{4}){3}-[a-f\\d]{12}?)', re.IGNORECASE)),\n",
      "('urn', re.compile(ur\"\\burn:[a-z0-9][a-z0-9-]{0,31}:[a-z0-9()+,\\-.:=@;$_!*'%/?#]+\", re.IGNORECASE)),\n",
      "('doi', re.compile(ur\"(10[.][0-9]{4,}(?:[/][0-9]+)*/(?:(?![\\\"&\\\\'])\\S)+)\", re.IGNORECASE)),\n",
      "('urn', re.compile(ur\"(oai:[a-z0-9.][a-z0-9-.]{0,31}:[a-z0-9()+,\\-.:=@;$_!*'%/?#]+)\", re.IGNORECASE))\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# extract by element ruleset\n",
      "\n",
      "# \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let's make a ruleset based on identified patterns:\n",
      "# http://philarcher.org/diary/2013/uripersistence/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# run the checks\n",
      "\n",
      "for kind, url in url_sampleset:\n",
      "    path = return_path(url)\n",
      "    query = return_parameter_values(url)\n",
      "    for pttn_type, pattern in pattern_set:\n",
      "        m = match(path, pattern)\n",
      "        if m:\n",
      "            print 'found URL match: {0}, {1}'.format(m, path)\n",
      "            print '\\tExpected {0}? {1}'.format(kind, kind==pttn_type)\n",
      "            break\n",
      "        \n",
      "        m = match(query, pattern)\n",
      "        if m:\n",
      "            print 'found QUERY match: {0}, {1}'.format(m, query)\n",
      "            print '\\tExpected {0}? {1}'.format(kind, kind==pttn_type)\n",
      "            break\n",
      "       "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "found URL match: b1b6e62a-cc9b-4cf5-89e5-d280e854eb1c, /harvest/object/b1b6e62a-cc9b-4cf5-89e5-d280e854eb1c\n",
        "\tExpected uuid? True\n",
        "found URL match: 2ee5666a-2f9e-4e69-997f-474737fcce71, /harvest/object/2ee5666a-2f9e-4e69-997f-474737fcce71/original\n",
        "\tExpected uuid? True\n",
        "found QUERY match: oai:openknowledge.worldbank.org:10986/18612, verb=GetRecord&metadataPrefix=oai_dc&identifier=oai:openknowledge.worldbank.org:10986/18612\n",
        "\tExpected urn? True\n",
        "found QUERY match: 6FCC9928-1352-44F3-9D7B-BBDC9AF15E9A, id={6FCC9928-1352-44F3-9D7B-BBDC9AF15E9A}\n",
        "\tExpected uuid? True\n",
        "found URL match: 35946660-26d0-4d05-955f-8af7ced2b0c1, /apps/rgis/datasets/35946660-26d0-4d05-955f-8af7ced2b0c1/metadata/FGDC-STD-001-1998.xml\n",
        "\tExpected uuid? True\n",
        "found URL match: 1abbc9be-1014-45ac-a281-808310790c31, /search/full/catalogue/dassh.ac.uk__MEDIN_2.3__CEFAS1abbc9be-1014-45ac-a281-808310790c31.xml/DIF_9.4\n",
        "\tExpected uuid? True\n",
        "found URL match: 10.14457/KU.THE.2006.802, /10.14457/KU.THE.2006.802\n",
        "\tExpected doi? True\n",
        "found URL match: 10.4224/20386605, /10.4224/20386605\n",
        "\tExpected doi? True\n",
        "found URL match: 10.1007/1-4020-3880-1_85, /referenceworkentry/10.1007/1-4020-3880-1_85\n",
        "\tExpected doi? True\n",
        "found QUERY match: urn:ogc:def:crs:EPSG::4979, wkt=urn:ogc:def:crs:EPSG::4979\n",
        "\tExpected urn? True\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "notes:\n",
      "\n",
      "urn regex(es) unlikely to be very generalized right now.\n",
      "\n",
      "ugh. text. and rss. and encoded html in the rss with the identifiers.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "building the test set. get the responses for the test urls (find identifer from url in response?)\n",
      "\n",
      "go get our known similarity (ie duplicates as different representations) set and try on those responses."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "import json\n",
      "from lxml import etree\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# the array of any identifiers found in a url\n",
      "# as (source url, identifier)\n",
      "_found_identifiers = []\n",
      "\n",
      "def un_htmlify(text):\n",
      "    # for cdata wrapped things? this is unpleasant\n",
      "    # but we want identifiers in the rss/atom element\n",
      "    # wrapped in cdata as encoded html\n",
      "    soup = BeautifulSoup(text.strip())\n",
      "    \n",
      "    # get all of the text and any a/@href values\n",
      "    texts = soup.find_all(text=True) + [unquote(a['href']) for a in soup.find_all('a')]\n",
      "    return ' '.join(text)\n",
      "\n",
      "class Parser():\n",
      "    def __init__(self, text):\n",
      "        self.text = text\n",
      "        self.parser = etree.XMLParser(\n",
      "            remove_blank_text=True, \n",
      "            remove_comments=True, \n",
      "            recover=True\n",
      "        )\n",
      "        \n",
      "    def _parse(self):\n",
      "        try:\n",
      "            self.xml = etree.fromstring(text, parser=self.parser)\n",
      "        except:\n",
      "            raise\n",
      "    \n",
      "    def strip_text(self):\n",
      "        # pull any text() and attribute. again.\n",
      "        # bag of words BUT we care about where in\n",
      "        # the tree it was found (just for thinking)\n",
      "        # except do not care about namespace prefixed\n",
      "        # why am i not stripping out the prefixes? no idea.\n",
      "        \n",
      "        def _extract_tag(t):\n",
      "            if not t:\n",
      "                return\n",
      "            return t.split('}')[-1]\n",
      "            \n",
      "        def _taggify(e):\n",
      "            tags = [e.tag] + [m.tag for m in e.iterancestors()]\n",
      "            tags.reverse()\n",
      "            return [_extract_tag(t) for t in tags]\n",
      "        \n",
      "        blobs = []\n",
      "        for elem in self.xml.iter():\n",
      "            t = elem.text.strip() if elem.text else ''\n",
      "            tags = _taggify(elem)\n",
      "            \n",
      "            if t:\n",
      "                blobs.append(('/'.join(tags), t))\n",
      "            \n",
      "            for k, v in elem.attrib.iteritems():\n",
      "                if v.strip():\n",
      "                    blobs.append(('/'.join(tags + ['@' + _extract_tag(k)]), v.strip()))\n",
      "        \n",
      "        return blobs\n",
      "            \n",
      "def process_tuple(t):\n",
      "    # check for html, get that as a bag of space-delimited words\n",
      "    # run some regex for identifiers\n",
      "    tags = t[0]\n",
      "    text = t[1]\n",
      "    \n",
      "    if text.startswith('<') and text.endswith('>'):\n",
      "        text = un_htmlify(text)\n",
      "    \n",
      "    # look for *new* identifiers\n",
      "    new_identifiers = []\n",
      "    for pttn_type, pattern in pattern_set:\n",
      "        m = match(text, pattern)\n",
      "        if m:\n",
      "            new_identifiers.append((pttn_type, m))\n",
      "            # return (tags, text, pttn_type)\n",
      "        \n",
      "    # look for existing identifiers\n",
      "    # this is not good - shift to some db solution (elasticsearch)\n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "for f in files:\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lxml import etree\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def _has_id(tag):\n",
      "    return tag.has_attr('id') or tag.has_attr('ID') or tag.has_attr('GUID')\n",
      "\n",
      "t = '''<description>\n",
      "                <![CDATA[\n",
      "<div class=\"snippet\" id=\"uuid23\"><div class=\"abstract\" style=\"overflow: auto;\" >\n",
      "WaveWatch III ocean wave model products from Will Perry and Bechara Toulany, Bedford Institute of Oceanography, Canada.\n",
      "</div><div class=\"links\"><A HREF=\"http://www.neracoos.org/thredds/wms/WW3/NorthAtlantic.nc?service=WMS&amp;version=1.3.0&amp;request=GetCapabilities\" target=\"_blank\">Open</A><A HREF=\"http://ngdc.noaa.gov/geoportal/catalog/search/resource/livedata-preview.page?uuid=%7B2B22E3FA-5D24-4413-BB93-87CBE51E0F64%7D&amp;url=http%3A%2F%2Fwww.neracoos.org%2Fthredds%2Fwms%2FWW3%2FNorthAtlantic.nc%3Fservice%3DWMS%26version%3D1.3.0%26request%3DGetCapabilities&amp;resourceType=wms&amp;info=http%3A%2F%2Fngdc.noaa.gov%2Fgeoportal%2Frest%2Fdocument%3Ff%3Dhtml%26showRelativeUrl%3Dtrue%26id%3D%257B2B22E3FA-5D24-4413-BB93-87CBE51E0F64%257D\" target=\"_blank\">Preview</A><A HREF=\"http://ngdc.noaa.gov/geoportal/catalog/search/resource/details.page?uuid=%7B2B22E3FA-5D24-4413-BB93-87CBE51E0F64%7D\" target=\"_blank\">Details</A><A HREF=\"http://ngdc.noaa.gov/geoportal/rest/document?id=%7B2B22E3FA-5D24-4413-BB93-87CBE51E0F64%7D\" target=\"_blank\">Metadata</A><A HREF=\"http://www.neracoos.org/thredds/wms/WW3/NorthAtlantic.nc?service=WMS&amp;version=1.3.0&amp;request=GetCapabilities\" target=\"_blank\">WMS</A><A HREF=\"http://www.neracoos.org/thredds/dodsC/WW3/NorthAtlantic.nc.html\" target=\"_blank\">Download</A><A HREF=\"http://www.neracoos.org/thredds/dodsC/WW3/NorthAtlantic.nc\" target=\"_blank\">OPeNDAP</A></div></div>\n",
      "]]>\n",
      "            </description>'''\n",
      "\n",
      "xml = etree.fromstring(t)\n",
      "\n",
      "print etree.tostring(xml)\n",
      "\n",
      "text = xml.text.strip()\n",
      "\n",
      "print text.startswith('<') and text.endswith('>'), text[0:10]\n",
      "\n",
      "soup = BeautifulSoup(text)\n",
      "\n",
      "# [i for i in soup.stripped_strings]\n",
      "\n",
      "soup.find_all(text=True)+[a['href'] for a in soup.find_all('a')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<description>\n",
        "                \n",
        "&lt;div class=\"snippet\" id=\"uuid23\"&gt;&lt;div class=\"abstract\" style=\"overflow: auto;\" &gt;\n",
        "WaveWatch III ocean wave model products from Will Perry and Bechara Toulany, Bedford Institute of Oceanography, Canada.\n",
        "&lt;/div&gt;&lt;div class=\"links\"&gt;&lt;A HREF=\"http://www.neracoos.org/thredds/wms/WW3/NorthAtlantic.nc?service=WMS&amp;amp;version=1.3.0&amp;amp;request=GetCapabilities\" target=\"_blank\"&gt;Open&lt;/A&gt;&lt;A HREF=\"http://ngdc.noaa.gov/geoportal/catalog/search/resource/livedata-preview.page?uuid=%7B2B22E3FA-5D24-4413-BB93-87CBE51E0F64%7D&amp;amp;url=http%3A%2F%2Fwww.neracoos.org%2Fthredds%2Fwms%2FWW3%2FNorthAtlantic.nc%3Fservice%3DWMS%26version%3D1.3.0%26request%3DGetCapabilities&amp;amp;resourceType=wms&amp;amp;info=http%3A%2F%2Fngdc.noaa.gov%2Fgeoportal%2Frest%2Fdocument%3Ff%3Dhtml%26showRelativeUrl%3Dtrue%26id%3D%257B2B22E3FA-5D24-4413-BB93-87CBE51E0F64%257D\" target=\"_blank\"&gt;Preview&lt;/A&gt;&lt;A HREF=\"http://ngdc.noaa.gov/geoportal/catalog/search/resource/details.page?uuid=%7B2B22E3FA-5D24-4413-BB93-87CBE51E0F64%7D\" target=\"_blank\"&gt;Details&lt;/A&gt;&lt;A HREF=\"http://ngdc.noaa.gov/geoportal/rest/document?id=%7B2B22E3FA-5D24-4413-BB93-87CBE51E0F64%7D\" target=\"_blank\"&gt;Metadata&lt;/A&gt;&lt;A HREF=\"http://www.neracoos.org/thredds/wms/WW3/NorthAtlantic.nc?service=WMS&amp;amp;version=1.3.0&amp;amp;request=GetCapabilities\" target=\"_blank\"&gt;WMS&lt;/A&gt;&lt;A HREF=\"http://www.neracoos.org/thredds/dodsC/WW3/NorthAtlantic.nc.html\" target=\"_blank\"&gt;Download&lt;/A&gt;&lt;A HREF=\"http://www.neracoos.org/thredds/dodsC/WW3/NorthAtlantic.nc\" target=\"_blank\"&gt;OPeNDAP&lt;/A&gt;&lt;/div&gt;&lt;/div&gt;\n",
        "\n",
        "            </description>\n",
        "True <div class\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "[u'\\nWaveWatch III ocean wave model products from Will Perry and Bechara Toulany, Bedford Institute of Oceanography, Canada.\\n',\n",
        " u'Open',\n",
        " u'Preview',\n",
        " u'Details',\n",
        " u'Metadata',\n",
        " u'WMS',\n",
        " u'Download',\n",
        " u'OPeNDAP',\n",
        " 'http://www.neracoos.org/thredds/wms/WW3/NorthAtlantic.nc?service=WMS&version=1.3.0&request=GetCapabilities',\n",
        " 'http://ngdc.noaa.gov/geoportal/catalog/search/resource/livedata-preview.page?uuid=%7B2B22E3FA-5D24-4413-BB93-87CBE51E0F64%7D&url=http%3A%2F%2Fwww.neracoos.org%2Fthredds%2Fwms%2FWW3%2FNorthAtlantic.nc%3Fservice%3DWMS%26version%3D1.3.0%26request%3DGetCapabilities&resourceType=wms&info=http%3A%2F%2Fngdc.noaa.gov%2Fgeoportal%2Frest%2Fdocument%3Ff%3Dhtml%26showRelativeUrl%3Dtrue%26id%3D%257B2B22E3FA-5D24-4413-BB93-87CBE51E0F64%257D',\n",
        " 'http://ngdc.noaa.gov/geoportal/catalog/search/resource/details.page?uuid=%7B2B22E3FA-5D24-4413-BB93-87CBE51E0F64%7D',\n",
        " 'http://ngdc.noaa.gov/geoportal/rest/document?id=%7B2B22E3FA-5D24-4413-BB93-87CBE51E0F64%7D',\n",
        " 'http://www.neracoos.org/thredds/wms/WW3/NorthAtlantic.nc?service=WMS&version=1.3.0&request=GetCapabilities',\n",
        " 'http://www.neracoos.org/thredds/dodsC/WW3/NorthAtlantic.nc.html',\n",
        " 'http://www.neracoos.org/thredds/dodsC/WW3/NorthAtlantic.nc']"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "some urn uuid examples:\n",
      "\n",
      "http://uaf.nodc.noaa.gov/geoportal/rest/find/document?max=5&f=atom&searchText=\n",
      "\n",
      "cdata fun:\n",
      "\n",
      "http://ngdc.noaa.gov/geoportal/rest/find/document?searchText="
     ]
    }
   ],
   "metadata": {}
  }
 ]
}