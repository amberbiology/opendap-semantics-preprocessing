{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new identification widgetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from itertools import chain\n",
    "from semproc.yaml_configs import import_yaml_configs\n",
    "from semproc.parser import Parser\n",
    "from semproc.rawresponse import RawResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Identify():\n",
    "    '''\n",
    "    parameters:\n",
    "        yaml_file: path to the yaml definition yaml\n",
    "        source_content: the content string for comparisons\n",
    "        source_url: the url string for comparisons\n",
    "        options: dict containing the filtering options, ie\n",
    "                 identify which protocol, identify which service\n",
    "                 of a protocol, identify if it's a dataset service\n",
    "                 for a protocol\n",
    "    '''\n",
    "    def __init__(self, yaml_files, source_content, source_url):\n",
    "        '''\n",
    "        **options:\n",
    "            parser: Parser from source_content\n",
    "            ignore_case: bool\n",
    "        '''\n",
    "        self.source_content = source_content\n",
    "        self.source_url = source_url\n",
    "        self.yaml = import_yaml_configs(yaml_files)\n",
    "        \n",
    "        self.parser = Parser(source_content)\n",
    "        \n",
    "\n",
    "    def _filter(self, operator, filters, clauses):\n",
    "        '''\n",
    "        generate a list of dicts for operator and booleans\n",
    "        that can be rolled up into some bool for a match\n",
    "        '''\n",
    "        for f in filters:\n",
    "            filter_type = f['type']\n",
    "\n",
    "            if filter_type == 'complex':\n",
    "                filter_operator = f['operator']\n",
    "                clauses.append(self._filter(filter_operator, f['filters'], []))\n",
    "            elif filter_type == 'simple':\n",
    "                filter_object = self.source_content if f['object'] == 'content' else self.source_url\n",
    "                filter_value = f['value']\n",
    "\n",
    "                # TODO: a better solution than this\n",
    "                filter_value = filter_value.upper()\n",
    "                filter_object = filter_object.upper()\n",
    "                \n",
    "                clauses.append(filter_value in filter_object)\n",
    "            elif filter_type == 'regex':\n",
    "                filter_object = self.source_content if f['object'] == 'content' else self.source_url\n",
    "                filter_value = f['value']\n",
    "                clauses.append(len(re.findall(filter_value, filter_object)) > 0)\n",
    "            elif filter_type == 'xpath':\n",
    "                # if the filter is xpath, we can only run against\n",
    "                # the provided xml (parser) and ONLY evaluate for existence\n",
    "                # ie the xpath returned some element, list, text value\n",
    "                # but we don't care what it returned\n",
    "                xpath = f['value']\n",
    "                if not self.parser:\n",
    "                    # nothing to find, this is an incorrect filter\n",
    "                    clauses.append(False)\n",
    "\n",
    "                # try the xpath but there could be namespace or\n",
    "                # other issues (also false negatives!)\n",
    "                try:\n",
    "                    clause = self.parser.xml.xpath(xpath) not in [None, '', []]\n",
    "                except:\n",
    "                    clause = False\n",
    "\n",
    "                clauses.append(clause)\n",
    "\n",
    "        return {operator: clauses}\n",
    "\n",
    "    def _evaluate(self, clauses, sums):\n",
    "        '''\n",
    "        evaluate a list a dicts where the key is\n",
    "        the operator and the value is a list of\n",
    "        booleans\n",
    "        '''\n",
    "        if isinstance(clauses, bool):\n",
    "            # so this should be the rolled up value\n",
    "            return clauses\n",
    "\n",
    "        for k, v in clauses.iteritems():\n",
    "            if isinstance(v, dict):\n",
    "                return sums + self._evaluate(v, 0)\n",
    "            elif isinstance(v, list) and not all(isinstance(i, bool) for i in v):\n",
    "                # TODO: this is not a good assumption\n",
    "                for i in v:\n",
    "                    sums += self._evaluate(i, 0)\n",
    "                return sums\n",
    "            if k == 'ands':\n",
    "                # everything must be true\n",
    "                sums += sum(v) == len(v)\n",
    "            elif k == 'ors':\n",
    "                # any one must be true\n",
    "                sums += sum(v) > 0\n",
    "\n",
    "        return sums\n",
    "\n",
    "    def identify(self):\n",
    "        '''\n",
    "        it is within a protocol if *any* set of filters\n",
    "        '''\n",
    "        def _test_option(filters):\n",
    "            '''where filters is the set of filters as booleans'''\n",
    "            if not filters:\n",
    "                return False\n",
    "            \n",
    "            for i, j in filters.iteritems():\n",
    "                if self._evaluate({i: self._filter(i, j, [])}, 0):\n",
    "                    return True\n",
    "                \n",
    "            return False\n",
    "        \n",
    "        def _extract_option(filters):\n",
    "            '''\n",
    "            where filters is the set of things to return a value\n",
    "            this assumes that you have concatenated the defaults and/or checks set\n",
    "            '''\n",
    "            if not filters:\n",
    "                return []\n",
    "            \n",
    "            items = []\n",
    "            for check in filters:\n",
    "                for c in check[1]:\n",
    "                    item = ''\n",
    "                    if c['type'] == 'simple':\n",
    "                        # TODO: this is still not a safe assumption re: casing\n",
    "                        filter_value = c['value'].upper()\n",
    "                        filter_object = self.source_content if c['object'] == 'content' else self.source_url\n",
    "                        filter_object = filter_object.upper()\n",
    "                        \n",
    "                        if filter_value in filter_object:\n",
    "                            item = [c.get('text', '')]  # just for the xpath handling later\n",
    "                    elif c['type'] == 'xpath':\n",
    "                        if not self.parser.xml:\n",
    "                            print 'Parser FAIL'\n",
    "                            continue\n",
    "                        \n",
    "                        try:\n",
    "                            values = self.parser.xml.xpath(c['value'])\n",
    "                            item = [v.strip() for v in values if v is not None]\n",
    "                        except Exception as ex:\n",
    "                            print 'XPATH FAIL: ', ex \n",
    "                            print c['value']\n",
    "                            continue\n",
    "                    \n",
    "                    if item:\n",
    "                        items += item\n",
    "            \n",
    "            return items\n",
    "        \n",
    "        def _chain(source_dict, keys):\n",
    "            if not source_dict:\n",
    "                return []\n",
    "            return list(chain.from_iterable(\n",
    "                    [source_dict.get(key, {}).items() for key in keys]\n",
    "                ))\n",
    "        \n",
    "        matches = []\n",
    "        for protocol in self.yaml:\n",
    "            protocol_name = protocol['name']\n",
    "            # print protocol_name\n",
    "\n",
    "            for k, v in protocol.iteritems():\n",
    "                if k in ['name'] or v is None:\n",
    "                    continue\n",
    "\n",
    "                for option in v:\n",
    "                    is_match = _test_option(option['filters'])\n",
    "                            \n",
    "                    # check the error filters\n",
    "                    errors = option.get('errors', {})\n",
    "                    is_error = _test_option(errors.get('filters', {})) if errors else False\n",
    "\n",
    "                    # check the language filters\n",
    "                    language_filters = option.get('language', {})\n",
    "                    _filters = _chain(language_filters, [\"defaults\", \"checks\"])\n",
    "                    languages = _extract_option(_filters)\n",
    "\n",
    "                    # check the version filters\n",
    "                    version_filters = option.get('versions', {})\n",
    "                    _filters = _chain(version_filters, [\"defaults\", \"checks\"])\n",
    "                    versions = _extract_option(_filters)\n",
    "                    \n",
    "                    # and the dialect if there's a key\n",
    "                    dialect_filters = option.get('dialect', {})\n",
    "                    if dialect_filters:\n",
    "                        if 'text' in dialect_filters:\n",
    "                            dialect = dialect_filters.get('text')\n",
    "                        else:\n",
    "                            # it's in the response somewhere\n",
    "                            _filters = _chain(dialect_filters, [\"defaults\", \"checks\"])\n",
    "                            dialect = _extract_option(_filters)\n",
    "                    \n",
    "\n",
    "                    # dump it out\n",
    "                    if is_match:\n",
    "                        matches.append({\n",
    "                                \"protocol\": protocol_name, \n",
    "                                \"type\": k,\n",
    "                                \"type_name\": option.get('name', ''),\n",
    "                                \"request\": option.get('request', ''),\n",
    "                                \"dialect\": dialect,\n",
    "                                \"version\": versions,\n",
    "                                \"error\": is_error,\n",
    "                                \"language\": languages\n",
    "                            })\n",
    "\n",
    "        return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:133: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'dialect': ['oai_dc'],\n",
       "  'error': False,\n",
       "  'language': [],\n",
       "  'protocol': 'OAI-PMH',\n",
       "  'request': 'ListRecords',\n",
       "  'type': 'resultset',\n",
       "  'type_name': 'OAI-PMH',\n",
       "  'version': []},\n",
       " {'dialect': ['oai_dc'],\n",
       "  'error': False,\n",
       "  'language': [],\n",
       "  'protocol': 'OAI-PMH',\n",
       "  'request': 'Identify',\n",
       "  'type': 'service',\n",
       "  'type_name': 'Identify',\n",
       "  'version': []}]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def _prep(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        response = f.read()\n",
    "\n",
    "    response = response.replace('\\\\\\n', '').replace('\\r\\n', '').replace('\\\\r', '').replace('\\\\n', '').replace('\\n', '')\n",
    "    return response.decode('utf-8', errors='replace').encode('unicode_escape')\n",
    "\n",
    "# print response\n",
    "\n",
    "#yamls = glob.glob('../semproc/configs/*_identifier.yaml')\n",
    "\n",
    "yamls = yamls = ['../semproc/configs/oaipmh_identifier.yaml']\n",
    "url = 'http://www.example.com?verb=ListRecords'\n",
    "response = _prep('../response_examples/oaipmh_listrecords.xml')\n",
    "\n",
    "# url = 'http://www.example.com/opensearch.xml'\n",
    "# response = _prep('../response_examples/opensearch_blended_parameters.xml')\n",
    "# response = _prep('../response_examples/opensearch_usgs_search_atom.xml')\n",
    "\n",
    "# yamls = ['../semproc/configs/opensearch_identifier.yaml', \n",
    "#          '../semproc/configs/iso_identifier.yaml']\n",
    "\n",
    "identifier = Identify(yamls, response, url)\n",
    "identifier.identify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'http://a9.com/-/spec/opensearch/1.1/' in response and 'http://www.w3.org/2005/Atom' in response and '<feed' in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "text = '''<feed xmlns=\"http://www.w3.org/2005/Atom\" xmlns:georss=\"http://www.georss.org/georss\"\n",
    " xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">\n",
    " <title>ScienceBase search results</title>\n",
    " <author>\n",
    "  <name>USGS ScienceBase</name>\n",
    "  <uri>http://www.sciencebase.gov/</uri>\n",
    " </author></feed>\n",
    "'''\n",
    "\n",
    "# this is ridiculous but it functions and won't be used (*shrugs*)\n",
    "def check_count(context, test, if_true=True, if_false=False):\n",
    "    print test, type(test)\n",
    "    return if_true if test else if_false\n",
    "ns = etree.FunctionNamespace(None)\n",
    "ns['check_count'] = check_count\n",
    "\n",
    "\n",
    "xml = etree.fromstring(text)\n",
    "\n",
    "# xml.xpath('check_count(count(/*/namespace::*[. = \"http://a9.com/-/spec/opensearch/1.1/\"]) = count(/*/namespace::*))')\n",
    "\n",
    "x = xml.xpath('count(/*/namespace::*[. = \"http://a9.com/-/spec/opensearch/1.1/\"]) < 1')\n",
    "\n",
    "'''\n",
    "- type: xpath-function\n",
    "    object: content\n",
    "    # make this some xpath expression that evaluates \n",
    "    # with a function *in* the code (not this one though it is not useful at all)\n",
    "    value: 'check_count(count(/*/namespace::*[. = \"http://a9.com/-/spec/opensearch/1.1/\"]) = count(/*/namespace::*)'\n",
    "    if_true: True\n",
    "    if_false: False \n",
    "'''\n",
    "\n",
    "print x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
